
# Three steps of prediction powered inference
# 1. Select the estimand theta* that is of interest
# 2. Specify the measure of fit and the rectifier
#    Measure of fit: discrepancy between estimand and estimate on the unlabeled data
#    Rectifier: discrepancy between the measure of fit on the labelled data, 
#    and on the labelled data with the predicted values instead of observed.
# 3. Calculate predicted-powered confidence intervals

# Example

set.seed(1)

N1 <- 10
N2 <- 90
N <- N1 + N2
P <- 3
m <- c(1,2,3)
S <- matrix(c(2,1,3,
              1,4,3,
              3,3,8),
            nrow = P, ncol = P)

b <- c(1, 0.5, 0.3, 0.1)

nsim <- 1000
CI_classical <- matrix(0, nsim, 2)
CI_pp <- matrix(0, nsim, 2)

EY <- c(1, m) %*% b

for (i in 1:nsim) {
  X <- rnorm(N*P) |> matrix(N) %*% chol(S) + matrix(m, N, P, byrow = TRUE)
  X1 <- X[1:N1,]
  X2 <- X[(N1+1):N,]
  Y1 <- cbind(1, X1) %*% b + rnorm(N1)
  
  # Fit a linear model
  fit <- lm(Y1 ~ X1)
  
  # Predict the outcome for the unlabeled data
  Y1hat <- predict(fit)
  Y2hat <- cbind(1, X2) %*% coef(fit)
  thetahat1 <- mean(Y1)
  thetahat1
  thetahat2 <- mean(Y2hat)
  thetahat2
  
  thetahatpp <- thetahat2 - mean(Y1hat - Y1)
  thetahatpp
  
  var1 <- 1/N1 * var(Y1)
  var2 <- 1/N2 * var(Y2hat)
  varpp <- var2 + 1/N1 * var(Y1hat - Y1)
  
  CI_classical[i,] <- thetahat1 + c(-1,1) * qt(0.975, df = N1) * sqrt(c(var1))
  CI_pp[i,] <- thetahatpp + c(-1,1) * qt(0.975, df = N1) * sqrt(c(varpp))
}

mean(CI_classical[,1] < c(EY) & CI_classical[,2] > c(EY))
mean(CI_pp[,1] < c(EY) & CI_pp[,2] > c(EY))

mean(CI_classical[,2] - CI_classical[,1])
mean(CI_pp[,2] - CI_pp[,1])

# The prediction-powered confidence intervals are slightly smaller than the
# classical confidence intervals, and the coverage is approximately the same.

for (i in 1:nsim) {
  X <- rnorm(N*P) |> matrix(N) %*% chol(S) + matrix(m, N, P, byrow = TRUE)
  X1 <- X[1:N1,]
  X2 <- X[(N1+1):N,]
  Y1 <- cbind(1, X1) %*% b + rnorm(N1)
  
  # Fit a linear model
  fit <- lm(Y1 ~ X1[,c(1,2)])

  # Predict the outcome for the unlabeled data
  Y1hat <- predict(fit)
  Y2hat <- cbind(1, X2[,c(1,2)]) %*% coef(fit)
  thetahat1 <- mean(Y1)
  thetahat1
  thetahat2 <- mean(Y2hat)
  thetahat2
  
  thetahatpp <- thetahat2 - mean(Y1hat - Y1)
  thetahatpp
  
  var1 <- 1/N1 * var(Y1)
  var2 <- 1/N2 * var(Y2hat)
  varpp <- var2 + 1/N1 * var(Y1hat - Y1)
  
  CI_classical[i,] <- thetahat1 + c(-1,1) * qt(0.975, N1) * sqrt(c(var1))
  CI_pp[i,] <- thetahatpp + c(-1,1) * qt(0.975, N1) * sqrt(c(varpp))
}

mean(CI_classical[,1] < c(EY) & CI_classical[,2] > c(EY))
mean(CI_pp[,1] < c(EY) & CI_pp[,2] > c(EY))

mean(CI_classical[,2] - CI_classical[,1])
mean(CI_pp[,2] - CI_pp[,1])

library(mice)

nsim <- 200

CI_mice <- matrix(0, nsim, 2)

for (i in 1:nsim) {
  cat("\rIteration: ", i)
  X <- rnorm(N*P) |> matrix(N) %*% chol(S) + matrix(m, N, P, byrow = TRUE)
  X1 <- X[1:N1,]
  X2 <- X[(N1+1):N,]
  Y1 <- cbind(1, X1) %*% b + rnorm(N1)
  
  df <- data.frame(Y = c(Y1, rep(NA, N2)),
                   rbind(X1, X2))
  
  imp <- mice(df, m = 100, maxit = 20, method = "norm", print = FALSE) |> complete("all")
  means  <- purrr::map_dbl(imp, ~mean(.x$Y))
  vars   <- purrr::map_dbl(imp, ~c(var(.x$Y))/N)
  pooled <- pool.scalar(means, vars, n = N)
  M <- pooled$qbar
  V <- pooled$t
  
  CI_mice[i, ] <- M + c(-1,1) * qt(0.975, df = pooled$df) * sqrt(V)
}

mean(CI_mice[,1] < c(EY) & CI_mice[,2] > c(EY))
mean(CI_mice[,2] - CI_mice[,1])
